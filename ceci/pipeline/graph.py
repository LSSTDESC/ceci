import networkx
import collections

def build_graph(stage_names, stage_classes, stage_aliases, overall_inputs):
    """
    Build a directed graph of the pipeline stages and their inputs and outputs.

    This also checks for various pipeline problems like missing inputs,
    multiple stages generating the same output, and cyclic dependencies.
    
    Parameters
    ----------
    stage_names : `list` of `str`
        The names of the stages in the pipeline
    stage_classes : `list` of `PipelineStage` subclasses
        The classes of the stages in the pipeline
    stage_aliases : `list` of `dict`
        A list of dictionaries mapping tags to aliases for each stage
    overall_inputs : `dict` of `str: str`
        A list of overall input files that are not generated by any stage but are needed by the pipeline

    Returns
    -------
    graph : `networkx.DiGraph`
        A directed graph representing the pipeline stages, their inputs, and outputs
    """

    # Build a graph with all the stages and files in it
    graph = networkx.DiGraph()

    # First add all the overall inputs
    for inp in overall_inputs:
        graph.add_node(inp, type="input")
    
    # Now go through all the stages. We do this in two passes,
    # one to add the stages themselves and their outputs, and one
    # to connect in all their inputs
    for stage_name, stage_class, aliases in zip(stage_names, stage_classes, stage_aliases):
        if stage_name in graph.nodes:
            raise ValueError(f"Stage {stage_name} is used multiple times in the pipeline")
        graph.add_node(stage_name, type="stage", stage_class=stage_class)

        # Now set up all the outputs of the stage, first checking to see if it has been aliased
        for tag in stage_class.output_tags():
            tag = aliases.get(tag, tag)
            if tag in overall_inputs:
                raise ValueError(f"Tag {tag} is generated by pipeline stage {stage_name} but is also listed as an overall input to the pipeline")
            graph.add_node(tag, type="output")
            graph.add_edge(stage_name, tag)

    # Now check for outputs that are generated by multiple stages
    for node in graph.nodes:
        if graph.nodes[node]["type"] == "output":
            parents = list(graph.predecessors(node))
            if len(parents) > 1:
                raise ValueError(f"Output {node} is generated by multiple stages: {parents}")
            

    # Now go through and add in all the inputs needed for each stage:
    missing = collections.defaultdict(list)
    for stage_name, stage_class, aliases in zip(stage_names, stage_classes, stage_aliases):
        for tag in stage_class.input_tags():
            tag = aliases.get(tag, tag)
            if tag not in graph.nodes:
                missing[tag].append(stage_name)
            else:
                graph.add_edge(tag, stage_name)
    
    if missing:
        msg = []
        for tag, stages in missing.items():
            stages = ", ".join(stages)
            msg.append(f"- {tag} - needed by stages {stages}")
        msg = "\n.join(msg)"
        raise ValueError(f"The following files are needed by the pipeline but not generated by any stage:\n{msg}")

    # Now check for cycles in the graph
    cycles = list(networkx.simple_cycles(graph))
    if cycles:
        msg = []
        for cycle in cycles:
            cycle_text = " -> ".join(cycle)
            cycle_text += " -> " + cycle[0]
            msg.append(f"- {cycle_text}")
        raise ValueError(f"Your pipeline is cyclic. The following cycles were found:\n{msg}")
    
    return graph

def get_static_ordering(graph):
    # get a topological ordering of the graph
    # this will be a list of all the nodes in the graph, including the input and output files
    ordering = list(networkx.topological_sort(graph))

    # cut down to just the stages
    ordering = [node for node in ordering if graph.nodes[node]["type"] == "stage"]
   
    return ordering